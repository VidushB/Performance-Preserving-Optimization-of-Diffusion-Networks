********** Running on Google Colab, testing purposes, single GPU **************************
!python3 /content/hpml_project/training.py
# specs->
# trainer = Trainer(
#     diffusion,
#     '/content/hpml_project/train',
#     train_batch_size = 128,
#     train_lr = 2e-4,
#     train_num_steps = 1000,
#     gradient_accumulate_every = 2,
#     ema_decay = 0.995,
#     amp = False
# )

loss: 0.1589: 100% 1000/1000 [12:29<00:00,  1.33it/s]
training complete
____________________________________________________________________

!python3 /content/hpml_project/training.py
# amp true ( faster by -4 mins)
# specs->
# trainer = Trainer(
#     diffusion,
#     '/content/hpml_project/train',
#     train_batch_size = 128,
#     train_lr = 2e-4,
#     train_num_steps = 1000,
#     gradient_accumulate_every = 2,
#     ema_decay = 0.995,
#     amp = True
# )

loss: 0.1690: 100% 1000/1000 [08:32<00:00,  1.95it/s]
training complete

____________________________________________________________________
# # Trying profiler :)
# import torch
# from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer

# model = Unet(
#     dim=64,
#     dim_mults=(1, 2, 4)
# ).cuda()

# diffusion = GaussianDiffusion(
#     model,
#     image_size=32,
#     timesteps=1000,
#     sampling_timesteps=250,
#     loss_type='l1'
# ).cuda()

# trainer = Trainer(
#     diffusion,
#     '/content/hpml_project/train',
#     train_batch_size=128,
#     train_lr=2e-4,
#     train_num_steps=1000,
#     gradient_accumulate_every=2,
#     ema_decay=0.995,
#     amp=True
# )

# def trace_handler(p):
#     output = p.key_averages().table(sort_by="self_cuda_time_total", row_limit=10)
#     print(output)
#     p.export_chrome_trace("/tmp/trace_" + str(p.step_num) + ".json")

# with torch.profiler.profile(
#     schedule=torch.profiler.schedule(
#         wait=2,
#         warmup=1,
#         active=3,
#         repeat=2
#     ),
#     on_trace_ready=trace_handler
# ) as profiler:
#     trainer.train()

************************ Important TEST *******************************************
->>>>>>>>>  No output in the directory, code runs tho!






******************************** TESTING PROFILER ONLY ************************************
#!/usr/bin/env python
# coding: utf-8


# In[ ]:
"""
PROFILING
import torch
from torch.profiler import profile, record_function, ProfilerActivity
from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer

model = Unet(
    dim=64,
    dim_mults=(1, 2, 4)
).cuda()

diffusion = GaussianDiffusion(
    model,
    image_size=32,
    timesteps=1000,
    sampling_timesteps=250,
    loss_type='l1'
).cuda()

trainer = Trainer(
    diffusion,
    '/content/hpml_project/train',
    train_batch_size=128,
    train_lr=2e-4,
    train_num_steps=1000,
    gradient_accumulate_every=2,
    ema_decay=0.995,
    amp=False
)

with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    record_shapes=True,
    profile_memory=True,
    with_stack=True,
    use_cuda=True
) as prof:
    trainer.train()

print(prof.key_averages().table(sort_by="self_cpu_time_total", row_limit=10))

----------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RESULTS: 
                         COMMENT RUN OUT OF RAM
/usr/local/lib/python3.10/dist-packages/torch/profiler/profiler.py:433: UserWarning: use_cuda is deprecated, use activities argument instead
  warn("use_cuda is deprecated, use activities argument instead")
STAGE:2023-05-10 01:53:37 5910:5910 ActivityProfilerController.cpp:311] Completed Stage: Warm Up
loss: 0.8834:   0% 0/100 [00:03<?, ?it/s][W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
loss: 0.2505: 100% 100/100 [01:20<00:00,  1.25it/s]
training complete
STAGE:2023-05-10 01:55:08 5910:5910 ActivityProfilerController.cpp:317] Completed Stage: Collection
STAGE:2023-05-10 01:55:11 5910:5910 ActivityProfilerController.cpp:321] Completed Stage: Post Processing




********************************************** SCRIPTING ************************************
import torch
import torch.jit
from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer

model = Unet(
    dim=64,
    dim_mults=(1, 2, 4)
).cuda()

diffusion = GaussianDiffusion(
    model,
    image_size=32,
    timesteps=1000,
    sampling_timesteps=250,
    loss_type='l1'
).cuda()

trainer = Trainer(
    diffusion,
    '/content/hpml_project/train',
    train_batch_size=128,
    train_lr=2e-4,
    train_num_steps=1000,
    gradient_accumulate_every=2,
    ema_decay=0.995,
    amp=False
)

# Convert the trainer to a script
scripted_trainer = torch.jit.script(trainer)

# Save the script to a file
torch.jit.save(scripted_trainer, "trainer.pt")

----------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
RESULTS: 
        RAM??????????????














**************************************** TRACING ********************************
"""
TRACING
"""
import torch
import torch.jit
from denoising_diffusion_pytorch import Unet

model = Unet(
    dim=64,
    dim_mults=(1, 2, 4)
).cuda()

# Create an example input tensor
x = torch.randn(1, 3, 32, 32).cuda()
time = torch.rand(1)
# Trace the model with the example input
traced_model = torch.jit.trace(model, (x,time))

# Call the traced model on the input to perform a forward pass and get the output
output = traced_model(x,time)

# Print the output
print(output)


tensor([[[[ 0.0261, -0.0281,  0.0562,  ..., -0.1251, -0.3131, -0.0716],
          [-0.1296, -0.4396, -0.3792,  ..., -0.5265, -0.0437, -0.2751],
          [-0.2136, -0.2105,  0.0296,  ..., -0.7300, -0.4346, -0.2069],
          ...,
          [ 0.2235, -0.1049,  0.0889,  ..., -0.2204, -0.0316, -0.4155],
          [-0.3604, -0.1003, -0.3326,  ..., -0.0584, -0.1938, -0.1592],
          [-0.3400, -0.3342, -0.3907,  ..., -0.3797, -0.2669, -0.1880]],

         [[ 0.1807,  0.4241,  0.3228,  ...,  0.2081,  0.3042, -0.1797],
          [ 0.5666,  0.2591,  0.4559,  ...,  0.8766,  0.4347,  0.1400],
          [ 0.1974,  0.3560,  0.1786,  ...,  0.5648,  0.6248,  0.4016],
          ...,
          [ 0.1561,  0.8666, -0.0247,  ...,  1.0909,  0.0522,  0.3734],
          [-0.1535,  0.1234,  0.3857,  ...,  0.1315,  0.1603,  0.5494],
          [-0.0845,  0.0512,  0.0738,  ..., -0.0164,  0.0377,  0.1241]],

         [[-0.3325,  0.2119, -0.3131,  ..., -0.1766, -0.3813, -0.1262],
          [-0.1210,  0.1192, -0.0891,  ...,  0.0311, -0.1448, -0.2641],
          [-0.0864,  0.0560,  0.0783,  ..., -0.1807,  0.2821, -0.3373],
          ...,
          [-0.1777,  0.3985, -0.1260,  ..., -0.3815,  0.4197, -0.0252],
          [-0.1135, -0.3135,  0.1067,  ...,  0.0449,  0.2419, -0.0798],
          [-0.1252, -0.1705,  0.3183,  ..., -0.2573, -0.0461, -0.2611]]]],
       device='cuda:0', grad_fn=<ConvolutionBackward1>)
       
       
       
       
       
       
       
       
       
       
       
       
       
**************************************************** Scripting and testing
COMMENT GOT KILLED FOR RESOURCES, Went up to 80%
loss: 0.1874:  70% 7000/10000 [1:01:16<26:05,  1.92it/s]

import torch
import torch.jit
import matplotlib.pyplot as plt
from denoising_diffusion_pytorch import *

model = Unet(
    dim=64,
    dim_mults=(1, 2, 4)
).cuda()

diffusion = GaussianDiffusion(
    model,
    image_size=32,
    timesteps=1000,
    sampling_timesteps=250,
    loss_type='l1'
).cuda()

trainer = Trainer(
    diffusion,
    '/content/hpml_project/train',
    train_batch_size=128,
    train_lr=2e-4,
    train_num_steps=10000,
    gradient_accumulate_every=2,
    ema_decay=0.995,
    amp=True
)

training_losses=trainer.train() #Training original model without any changes or jit capabilites

# Generate sampled images
sampled_images = diffusion.sample(batch_size=9)

# Plot and save the sampled images
fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(10, 10))
for i in range(9):
    row = i // 3
    col = i % 3
    temp = sampled_images[i].detach().cpu().permute(1, 2, 0)
    axs[row, col].imshow(temp)
    axs[row, col].axis('off')

# Save the image as sampled.png
plt.savefig('/content/hpml_project/sampled.png', bbox_inches='tight', pad_inches=0)



# Create an example input tensor
x = torch.randn(1, 3, 32, 32).cuda()
time = torch.rand(1)

# Trace the model with the example input
traced_model = torch.jit.trace(model, (x,time))

# Call the traced model on the input to perform a forward pass and get the output
output = traced_model(x,time)

# Visualize the feature maps by plotting each channel as a grayscale image
fig, axs = plt.subplots(ncols=output.shape[1], figsize=(16, 4))
for i in range(output.shape[1]):
    axs[i].imshow(output[0, i].detach().cpu(), cmap='gray')
    axs[i].set_title(f'Channel {i+1}')
    axs[i].axis('off')

# Save the image as traced.png
plt.savefig('/content/hpml_project/traced.png')

import matplotlib.pyplot as plt

# Choose one of the output channels to visualize
channel_idx = 1

# Convert the output tensor to a numpy array and extract the channel
output_np = output.detach().cpu().numpy()[0, channel_idx]

# Plot the image using grayscale colormap
plt.imshow(output_np, cmap='gray')

# Remove the axis ticks
plt.xticks([])
plt.yticks([])

# Save the image as output.png
plt.savefig('/content/hpml_project/output.png', bbox_inches='tight', pad_inches=0)




TODO - CHECK OUT
https://gist.github.com/mingfeima/e08310d7e7bb9ae2a693adecf2d8a916
https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html
https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html
https://towardsdatascience.com/pytorch-jit-and-torchscript-c2a77bac0fff
